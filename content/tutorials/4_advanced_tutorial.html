---
extends: skeleton/_base.html
title: Advanced tutorial
---

{% block content %}

{% restructuredtext %}

What this tutorial is about?
============================
In this tutorial we will present more advanced features of Troia.
We will cover topics like incremental version of algorithm, marking objects as gold or checking which samples might require more assigns.

As in base tutorial we will use `cURL <http://curl.haxx.se/>`_ to communicate with Troia Server API.
Also we will use the same dataset in examples.


Incremental Dawid-Skene
-----------------------
In Troia we have two versions of Dawid-Skene algorithm.
Batch version requires user to inform Troia to preform some calculations explictly.
Incremental version doesn't require this.
It does some computations when you add some data to job or modify them.
From user point of view main difference is that it doesn't require to call **calculate** go give some meaningfull results.

Let see it in action.


Sample usage
++++++++++++

When you create job you can specify **type** parameter.
Default value is *batch*.
Other choice would be *incremental*.
It will result in creating job which uses incremental version of *Get-Another-Label* algorithm.


::

    curl -X POST -H "Content-Type: application/json" "http://project-troia.com/api/jobs" -d 'id=<JOB_ID>&type=incremental&categories=
    [{
        "prior":"1",
        "name":"porn",
        "misclassification_cost":
        {
            "porn":"0",
            "notporn":"1"
        }
    },
    {
        "prior":"1",
        "name":"notporn",
        "misclassification_cost":
        {
            "porn":"1",
            "notporn":"0"
        }
    }]'

Remember that we also need to send collection of **categories**, containing their names, priorities and misclassification costs matrix.


Similarly to basic tutorial we should now upload assigned labels.


After doing this we are ready to retrieve results.
For example to get predicted labels for all objects just call
::

    curl -X GET "http://project-troia.com/api/jobs/<JOB_ID>/prediction/data"

After going to redirect you should obtain:

::

    {
        "result": {
            "http://google.com": "notporn",
            "http://sex-mission.com": "porn",
            "http://sunnyfun.com": "notporn",
            "http://yahoo.com": "notporn",
            "http://youporn.com": "porn"
        },
        "status": "OK",
        "timestamp": "2013-01-15T15:53:30.378+01:00"
    }


To see label probability distribution for *http://yahoo.com*:

::

    curl -X GET "http://project-troia.com/api/jobs/<JOB_ID>/data/http://yahoo.com/categoryProbability

And after redirecting you should get:

::

    {
        "result": {
            "notporn": 0.97945,
            "porn": 0.02055
        },
        "status": "OK",
        "timestamp": "2013-01-15T15:56:15.429+01:00"
    }


Or we could ask for workers quality:

::

    "http://project-troia.com/api/jobs/<JOB_ID>/prediction/workersQuality"

And in result we should get:

::

    {
        "result": {
            "worker1": 0.8516375211366187,
            "worker2": 0.9011184676007533,
            "worker3": 0.9749015350602155,
            "worker4": 0.9749015350602155,
            "worker5": 0.8439714531050402
        },
        "status": "OK",
        "timestamp": "2013-01-16T15:48:05.842+01:00"
    }


Computation
+++++++++++

Basic calculations are done as we manipulate data.
We can force more computations.
More computations in some cases leads to better results.
This is true mostly for some complicated and huge data.

::

    curl -X POST -d "iterations=20" "http://project-troia.com/api/jobs/<JOB_ID>/compute"


Doing this on our example data changes label probability distribution for *http://yahoo.com*:

::

    curl -X GET "http://project-troia.com/api/jobs/<JOB_ID>/data/http://yahoo.com/categoryProbability

results with:

::

    {
        "result": {
            "notporn": 0.98,
            "porn": 0.02
        },
        "status": "OK",
        "timestamp": "2013-01-15T16:00:24.162+01:00"
    }


Marking object as gold
----------------------

Sometimes during collecting assigns we get to know true label for some sample.
This is knowledge that we might use to increase accuracy of Troia.

Lets initialize job with cost matrix and assigns from example.
We will work on *incremental* version as it doesn't require forcing computations.

We check workers qualities just after putting assigns:

::

    curl -X GET "http://project-troia.com/api/jobs/ADV_TUT/status/2"


We should get something like this (after redirect):

::

    {
        "result": {
            "worker1": 0.8516375211366187,
            "worker2": 0.9011184676007533,
            "worker3": 0.9749015350602155,
            "worker4": 0.9749015350602155,
            "worker5": 0.8439714531050402
        },
        "status": "OK",
        "timestamp": "2013-01-16T14:29:25.405+01:00"
    }


Now we mark object as gold:

::

    curl -X POST -H "Content-Type: application/json" "http://project-troia.com/api/jobs/ADV_TUT/goldData" -d 'labels=
    [{
        "correctCategory": "porn",
        "objectName": "http://sex-mission.com"
    }]'

And asking again for results we should get different results:

::

    {
        "result": {
            "worker1": 0.8516899142110332,
            "worker2": 0.9011936513308119,
            "worker3": 0.9749995850392734,
            "worker4": 0.9749995850392734,
            "worker5": 0.844066702629549
        },
        "status": "OK",
        "timestamp": "2013-01-16T16:52:31.560+01:00"
    }


Checking whether samples require more assigns
---------------------------------------------

Troia can determine whether there are samples for which we should provide more assigns in order to acquire more accurate results.
To do this we can use *data cost* functions.
It is related to fact that we can assign to different errors different costs.
For example predicting not porn site as porn is not as big problem as predicting porn site as not porn in case of program which should protect kids computer.

For our purposes of determining samples which require more assigns we will use variation called *expectedCost*.
This value for given object describes cost value that algorithm *expects* it will generate.
Lower value means that algorithm is more sure of its prediction and that it less require more data.

To acquire those estimated costs for all data:

::

    curl -X GET "http://project-troia.com/api/jobs/ADV_TUT/prediction/dataCost" -d "costAlgorithm=ExpectedCost"


On our basic example (without marking gold object) response shows that we have enough labels:

::

    {
        "result": {
            "http://google.com": 0.0032148158,
            "http://sex-mission.com": 0.0015388141999999997,
            "http://sunnyfun.com": 0.00029995499999999997,
            "http://yahoo.com": 0.00017998380000000002,
            "http://youporn.com": 0.040255395
        },
        "status": "OK",
        "timestamp": "2013-01-16T17:26:22.999+01:00"
    }

As we can see algorithm is less confident about last url than any other.


{% endrestructuredtext %}

{% endblock %}

